```markdown
# CS 487: Machine Learning and Adversarial Attacks

## Outcome:
1. Identify the vulnerabilities of machine learning models to various types of adversarial attacks.
2. Differentiate between adversarial evasion attacks in white-box and black-box settings and understand the principles of data poisoning attacks.
3. Explain the fundamentals of adversarial privacy attacks and outline privacy-preserving defense methods.
4. Describe jailbreak attacks on large language models and propose corresponding mitigation methods.
5. List common defense strategies against adversarial attacks and discuss approaches for improved robustness of machine learning models.
6. Identify the unique characteristics of adversarial attacks on machine learning models in the cybersecurity domain.
7. Implement adversarial attacks and defenses against conventional machine learning models and deep learning models.
8. Evaluate the effectiveness of adversarial attacks against anomaly detection systems for network intrusion detection, machine learning malware classifiers, and anti-spam filtering models.
9. Analyze the ethical and societal implications of adversarial attacks and defenses.

## Assignments:

### Assignment 1:
**Implement white-box evasion attacks against deep learning-based classification models.**

---

### Assignment 2:
#### Part 01:
**Implement white-box evasion attacks against deep learning-based classification models using the PyTorch library.**

#### Part 02:
**Implement transferable black-box evasion attacks against deep learning classification models.**
- Used dataset: [Objects.zip](https://drive.google.com/file/d/19uC4H5FRJCoEnBM9QufbeU_xOcPFssN4/view?usp=sharing)

---

### Assignment 3:
#### Part 01:
**Implement black-box boundary attack on deep learning-based classification models.**

#### Part 02:
**Implement adversarial training defense against evasion attacks on deep learning-based classification models.**
- Used dataset: [Painting.zip](https://drive.google.com/file/d/10iBXJ21wrdhuYjqDPq6oybF3K4x6m16-/view?usp=sharing)

---

### Assignment 4:
#### Part 01:
**Get familiar with deep learning models for Natural Language Processing (NLP), and implement adversarial attacks on NLP classification models.**

#### Part 02:
**Get familiar with fine-tuning Large Language Models (LLMs), and implement jailbreaking attacks on LLMs.**
```

This will give you a nicely formatted `README.md` that is clear and easy to read on GitHub. The links to the datasets are properly integrated, and each part of the assignment is separated to ensure clarity.
