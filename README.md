# ğŸ§  **CS 487: Machine Learning and Adversarial Attacks** ğŸ”

## ğŸ“š **Learning Outcomes:**
By the end of this course, you will:
- âš¡ Identify the vulnerabilities of machine learning models to various types of **adversarial attacks**.
- ğŸ” Differentiate between **white-box** and **black-box** adversarial evasion attacks and understand **data poisoning attacks**.
- ğŸ›¡ï¸ Explain the fundamentals of **adversarial privacy attacks** and outline **privacy-preserving defense** methods.
- ğŸš¨ Describe **jailbreak attacks** on large language models and propose corresponding **mitigation methods**.
- ğŸ” List common **defense strategies** against adversarial attacks and discuss approaches to improve the robustness of machine learning models.
- ğŸ–¥ï¸ Identify the unique characteristics of adversarial attacks on **machine learning models in cybersecurity**.
- ğŸ’» Implement adversarial attacks and defenses for both **conventional** and **deep learning models**.
- ğŸ§© Evaluate the effectiveness of adversarial attacks on **anomaly detection systems**, **network intrusion detection**, **malware classifiers**, and **anti-spam filtering models**.
- âš–ï¸ Analyze the **ethical and societal implications** of adversarial attacks and defenses.

---

## ğŸ“‘ **Assignments Overview:**

### **Assignment 1**: 
**ğŸš¨ White-box Evasion Attacks on Deep Learning Classification Models**
- **Objective**: Implement white-box adversarial evasion attacks on deep learning-based classification models.

---

### **Assignment 2**: 
**Part 01**:  
**ğŸ› ï¸ White-box Evasion Attacks using PyTorch**
- **Objective**: Implement white-box evasion attacks against deep learning-based classification models using the PyTorch library.

**Part 02**:  
**ğŸ¯ Transferable Black-box Evasion Attacks**
- **Objective**: Implement transferable black-box adversarial attacks on deep learning classification models.
- **Dataset Used**: [Objects.zip](https://drive.google.com/file/d/19uC4H5FRJCoEnBM9QufbeU_xOcPFssN4/view?usp=sharing)

---

### **Assignment 3**:  
**Part 01**:  
**ğŸ”’ Black-box Boundary Attack Implementation**
- **Objective**: Implement a black-box boundary attack on deep learning-based classification models.

**Part 02**:  
**ğŸ’¡ Adversarial Training Defense**
- **Objective**: Implement adversarial training defense to protect deep learning-based classification models against evasion attacks.
- **Dataset Used**: [Painting.zip](https://drive.google.com/file/d/10iBXJ21wrdhuYjqDPq6oybF3K4x6m16-/view?usp=sharing)

---

### **Assignment 4**:  
**Part 01**:  
**ğŸ“š Adversarial Attacks on NLP Classification Models**
- **Objective**: Explore deep learning models for NLP, and implement adversarial attacks on NLP classification models.

**Part 02**:  
**ğŸ§© Jailbreaking Attacks on Large Language Models (LLMs)**
- **Objective**: Get familiar with fine-tuning LLMs and implement jailbreaking attacks on them.

---

## ğŸ”— **Links to Datasets**:
- [Objects.zip](https://drive.google.com/file/d/19uC4H5FRJCoEnBM9QufbeU_xOcPFssN4/view?usp=sharing)
- [Painting.zip](https://drive.google.com/file/d/10iBXJ21wrdhuYjqDPq6oybF3K4x6m16-/view?usp=sharing)
