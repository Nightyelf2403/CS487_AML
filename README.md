# 🧠 **CS 487: Machine Learning and Adversarial Attacks** 🔐

## 📚 **Learning Outcomes:**
By the end of this course, you will:
- ⚡ Identify the vulnerabilities of machine learning models to various types of **adversarial attacks**.
- 🔍 Differentiate between **white-box** and **black-box** adversarial evasion attacks and understand **data poisoning attacks**.
- 🛡️ Explain the fundamentals of **adversarial privacy attacks** and outline **privacy-preserving defense** methods.
- 🚨 Describe **jailbreak attacks** on large language models and propose corresponding **mitigation methods**.
- 🔐 List common **defense strategies** against adversarial attacks and discuss approaches to improve the robustness of machine learning models.
- 🖥️ Identify the unique characteristics of adversarial attacks on **machine learning models in cybersecurity**.
- 💻 Implement adversarial attacks and defenses for both **conventional** and **deep learning models**.
- 🧩 Evaluate the effectiveness of adversarial attacks on **anomaly detection systems**, **network intrusion detection**, **malware classifiers**, and **anti-spam filtering models**.
- ⚖️ Analyze the **ethical and societal implications** of adversarial attacks and defenses.

---

## 📑 **Assignments Overview:**

### **Assignment 1**: 
**🚨 White-box Evasion Attacks on Deep Learning Classification Models**
- **Objective**: Implement white-box adversarial evasion attacks on deep learning-based classification models.

---

### **Assignment 2**: 
**Part 01**:  
**🛠️ White-box Evasion Attacks using PyTorch**
- **Objective**: Implement white-box evasion attacks against deep learning-based classification models using the PyTorch library.

**Part 02**:  
**🎯 Transferable Black-box Evasion Attacks**
- **Objective**: Implement transferable black-box adversarial attacks on deep learning classification models.
- **Dataset Used**: [Objects.zip](https://drive.google.com/file/d/19uC4H5FRJCoEnBM9QufbeU_xOcPFssN4/view?usp=sharing)

---

### **Assignment 3**:  
**Part 01**:  
**🔒 Black-box Boundary Attack Implementation**
- **Objective**: Implement a black-box boundary attack on deep learning-based classification models.

**Part 02**:  
**💡 Adversarial Training Defense**
- **Objective**: Implement adversarial training defense to protect deep learning-based classification models against evasion attacks.
- **Dataset Used**: [Painting.zip](https://drive.google.com/file/d/10iBXJ21wrdhuYjqDPq6oybF3K4x6m16-/view?usp=sharing)

---

### **Assignment 4**:  
**Part 01**:  
**📚 Adversarial Attacks on NLP Classification Models**
- **Objective**: Explore deep learning models for NLP, and implement adversarial attacks on NLP classification models.

**Part 02**:  
**🧩 Jailbreaking Attacks on Large Language Models (LLMs)**
- **Objective**: Get familiar with fine-tuning LLMs and implement jailbreaking attacks on them.

---

## 🔗 **Links to Datasets**:
- [Objects.zip](https://drive.google.com/file/d/19uC4H5FRJCoEnBM9QufbeU_xOcPFssN4/view?usp=sharing)
- [Painting.zip](https://drive.google.com/file/d/10iBXJ21wrdhuYjqDPq6oybF3K4x6m16-/view?usp=sharing)
