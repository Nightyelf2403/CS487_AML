Cs 487 


Outcome:
1. Identify the vulnerabilities of machine learning models to various types of adversarial attacks.
2. Differentiate between adversarial evasion attacks in white-box and black-box settings and
understand the principles of data poisoning attacks.
3. Explain the fundamentals of adversarial privacy attacks and outline privacy-preserving defense
methods.
4. Describe jailbreak attacks on large language models and propose corresponding mitigation
methods.
5. List common defense strategies against adversarial attacks and discuss approaches for
improved robustness of machine learning models.
6. Identify the unique characteristics of adversarial attacks on machine learning models in the
cybersecurity domain.
7. Implement adversarial attacks and defenses against conventional machine learning models
and deep learning models.
8. Evaluate the effectiveness of adversarial attacks against anomaly detection systems for
network intrusion detection, machine learning malware classifiers, and anti-spam filtering
models.
9. Analyze the ethical and societal implications of adversarial attacks and defenses

    
Assignment1:
Implement white-box evasion attacks against deep learning-based classification models.

Assignment2:
**Part 01** Implement white-box evasion attacks against deep learning-based classification models using the
PyTorch library.
**Part 02** Implement transferable black-box evasion attack against deel learning classification models.

Assignment3:
**Part 01** Implement black-box boundary attack on deep learning-based classification models.
**Part 02** Implement adversarial training defense against evasion attacks on deep learning-based
classification models.
Used Painting.zip for Part 02 Cannot upload cause of the size placing the link here: https://drive.google.com/file/d/10iBXJ21wrdhuYjqDPq6oybF3K4x6m16-/view?usp=sharing

Assignment4:
**Part 01** To get familiar with deep learning models for Natural Language Processing (NLP), and implement
adversarial attacks on NLP classification models.
**Part 02** To get familiar with finetuning Large Language Models (LLMs), and implement jailbreaking attacks
on LLMs.
